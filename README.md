# NLP Text Classification with BERT

This project is part of the AIDI 1002 Final Project. It involves building a text classification model using both traditional and transformer-based approaches.

## üîç Objective

The main goal of this project is to classify whether a given tweet/text indicates a disaster or not.

## Project Structure

- `bert_text_classifier.py` ‚Äì BERT-based text classification model.
- `bert_predict_submission.py` ‚Äì Code for generating predictions on the test set using the trained BERT model.
- `bert_model.pth` ‚Äì Trained BERT model weights (stored locally).
- `train.csv`, `test.csv` ‚Äì Dataset files used for training and testing.
- `submission.csv` ‚Äì Output predictions for submission.
- `NLP text classification model Github.ipynb` ‚Äì Notebook showing traditional model pipeline.
- `README.md` ‚Äì Project overview and details.

## Models Used

- Logistic Regression (TF-IDF)
- Word2Vec
- **BERT (transformer-based)** ‚Äì added as a contribution to enhance the model.

## Dependencies

- Python 3.10+
- `torch`
- `transformers`
- `scikit-learn`
- `pandas`
- `numpy`

